{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"asebclass.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMm97yDX/Qv5/M76hzoS+O6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"rAvQI3c0z_IO","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd \n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","from tensorflow.keras import backend as K\n","import random\n","import os\n","\n","# Path for the images. Check ReadMe to download image data.\n","a_dir = os.path.join('rstrain_A_N/A')\n","b_dir = os.path.join('rstrain_A_N/B')\n","c_dir = os.path.join('rstrain_A_N/W')\n","\n","print('Total training A images:', len(os.listdir(a_dir)))\n","print('Total training B images:', len(os.listdir(b_dir)))\n","print('Total training W images:', len(os.listdir(c_dir)))\n","\n","a_files = os.listdir(a_dir)\n","#print(a_files[:10])\n","\n","b_files = os.listdir(b_dir)\n","#print(b_files[:10])\n","\n","c_files = os.listdir(c_dir)\n","#print(c_files[:10])\n","\n","img_width, img_height = 160, 120 # size of images\n","\n","\n","if K.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","#Defining image data directories and \n","\n","TRAINING_DIR = \"rstrain_A_N\"\n","training_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","VALIDATION_DIR = \"rsvalidation_A_N\"\n","validation_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","train_generator = training_datagen.flow_from_directory(\n","    TRAINING_DIR,\n","    target_size=(120,160),\n","    class_mode='categorical')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    VALIDATION_DIR,\n","    target_size=(120,160),\n","    class_mode='categorical')\n","\n","# ...\n","from tensorflow.keras import regularizers\n","model = tf.keras.models.Sequential([\n","    # First convolution\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', \n","                           kernel_regularizer=regularizers.l2(0.001),\n","                           input_shape=input_shape),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    \n","    # Second convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu', \n","                           kernel_regularizer=regularizers.l2(0.001)\n","                           ),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # The Third convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu',\n","                           kernel_regularizer=regularizers.l2(0.001)\n","                           ),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # Fourth convolution\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu',\n","                           kernel_regularizer=regularizers.l2(0.001)\n","                           ),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # Flatten and Dropout\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    \n","    # 128 neuron hidden layer\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","from tensorflow import keras\n","opt = keras.optimizers.Adam(learning_rate=10E-7)\n","\n","# Stop based on minimum validation loss with 10 step patience.\n","from tensorflow.keras.callbacks import EarlyStopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","\n","# Save checkpoint based on maximum validation accuracy (edit for appropriate path).\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","mc = ModelCheckpoint('/path/Mod_name.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","history = model.fit(train_generator, epochs=300, batch_size=64, validation_data = validation_generator, verbose = 1, callbacks=[es,mc])"],"execution_count":null,"outputs":[]}]}